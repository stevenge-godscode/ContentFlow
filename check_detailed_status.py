#!/usr/bin/env python3
"""
Genesis Connector è¯¦ç»†çŠ¶æ€ç›‘æ§å·¥å…·
åˆ†åˆ«æ˜¾ç¤ºï¼šå¾…å‘ç°ã€å¾…ä¸‹è½½ã€å¾…æå–ã€å·²å®Œæˆç­‰ç‹¬ç«‹çŠ¶æ€
"""

import requests
import json
import time
import os
import glob
from datetime import datetime
import subprocess
import sys

def get_service_status(url, service_name):
    """è·å–æœåŠ¡çŠ¶æ€"""
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            return {'status': 'online', 'data': response.json()}
        else:
            return {'status': 'error', 'error': f'HTTP {response.status_code}'}
    except requests.exceptions.ConnectionError:
        return {'status': 'offline', 'error': 'Connection refused'}
    except Exception as e:
        return {'status': 'error', 'error': str(e)}

def get_database_stats():
    """è·å–æ•°æ®åº“çŠ¶æ€ç»Ÿè®¡"""
    try:
        result = subprocess.run([
            'docker-compose', 'exec', '-T', 'postgres', 'psql',
            '-U', 'user', '-d', 'content_db', '-c',
            'SELECT download_status, parse_status, COUNT(*) as count FROM articles_status GROUP BY download_status, parse_status;'
        ], capture_output=True, text=True, timeout=10)

        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')[2:-1]  # è·³è¿‡æ ‡é¢˜å’Œæ€»è®¡è¡Œ
            stats = {}
            for line in lines:
                if '|' in line:
                    parts = [p.strip() for p in line.split('|')]
                    if len(parts) >= 3:
                        download_status = parts[0] if parts[0] else 'null'
                        parse_status = parts[1] if parts[1] else 'null'
                        count = int(parts[2])
                        key = f"{download_status}_{parse_status}"
                        stats[key] = count
            return stats
        else:
            return {}
    except Exception as e:
        return {}

def get_file_stats():
    """è·å–æ–‡ä»¶ç³»ç»Ÿç»Ÿè®¡"""
    try:
        html_dir = '/tmp/genesis-content/html'
        text_dir = '/tmp/genesis-content/text'
        metadata_dir = '/tmp/genesis-content/metadata'

        html_files = glob.glob(os.path.join(html_dir, "*.html"))
        text_files = glob.glob(os.path.join(text_dir, "*.txt"))
        metadata_files = glob.glob(os.path.join(metadata_dir, "*.json"))

        return {
            'html_count': len(html_files),
            'text_count': len(text_files),
            'metadata_count': len(metadata_files)
        }
    except Exception as e:
        return {'html_count': 0, 'text_count': 0, 'metadata_count': 0}

def analyze_processing_pipeline(services_info, db_stats, file_stats):
    """åˆ†æå¤„ç†æµæ°´çº¿çŠ¶æ€"""
    # ä»æœåŠ¡è·å–é˜Ÿåˆ—ä¿¡æ¯
    download_service = services_info.get('Download Service', {})
    extraction_service = services_info.get('Text Extraction Service', {})

    pipeline_stats = {
        'discovered_pending': 0,      # å·²å‘ç°å¾…ä¸‹è½½
        'downloading': 0,             # ä¸‹è½½ä¸­
        'download_completed': 0,      # ä¸‹è½½å®Œæˆå¾…æå–
        'extracting': 0,              # æå–ä¸­
        'completed': 0,               # å…¨éƒ¨å®Œæˆ
        'failed_download': 0,         # ä¸‹è½½å¤±è´¥
        'failed_extraction': 0        # æå–å¤±è´¥
    }

    # ä»æ•°æ®åº“çŠ¶æ€åˆ†æ
    for status_key, count in db_stats.items():
        download_status, parse_status = status_key.split('_')

        if download_status == 'pending' and parse_status == 'null':
            pipeline_stats['discovered_pending'] = count
        elif download_status == 'processing':
            pipeline_stats['downloading'] = count
        elif download_status == 'completed' and parse_status in ['null', 'pending']:
            pipeline_stats['download_completed'] = count
        elif parse_status == 'processing':
            pipeline_stats['extracting'] = count
        elif download_status == 'completed' and parse_status == 'completed':
            pipeline_stats['completed'] = count
        elif download_status == 'failed':
            pipeline_stats['failed_download'] = count
        elif parse_status == 'failed':
            pipeline_stats['failed_extraction'] = count

    # ä»æ–‡ä»¶ç³»ç»Ÿè·å–å®é™…å®Œæˆæ•°é‡
    actual_completed = min(file_stats['html_count'], file_stats['text_count'])
    pipeline_stats['actual_completed'] = actual_completed

    # ä»é˜Ÿåˆ—è·å–å®æ—¶ä¿¡æ¯
    if download_service.get('status') == 'online':
        queue_stats = download_service.get('data', {}).get('queue_stats', {})
        pipeline_stats['queue_download_pending'] = queue_stats.get('download_tasks_length', 0)
        pipeline_stats['queue_parse_pending'] = queue_stats.get('parse_tasks_length', 0)

    return pipeline_stats

def format_number(num):
    """æ ¼å¼åŒ–æ•°å­—"""
    if num >= 1000:
        return f"{num/1000:.1f}K"
    return str(num)

def print_header():
    """æ‰“å°æ ‡é¢˜"""
    print("=" * 80)
    print("ğŸ” Genesis Connector è¯¦ç»†çŠ¶æ€ç›‘æ§")
    print(f"â° æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

def print_pipeline_status(pipeline_stats):
    """æ‰“å°å¤„ç†æµæ°´çº¿çŠ¶æ€"""
    print(f"\nğŸš€ å†…å®¹å¤„ç†æµæ°´çº¿")
    print("-" * 50)

    # è®¡ç®—æ€»æ•°
    total_articles = (
        pipeline_stats['discovered_pending'] +
        pipeline_stats['downloading'] +
        pipeline_stats['download_completed'] +
        pipeline_stats['extracting'] +
        pipeline_stats['completed'] +
        pipeline_stats['failed_download'] +
        pipeline_stats['failed_extraction']
    )

    actual_completed = pipeline_stats['actual_completed']

    print(f"ğŸ“Š æ€»æ–‡ç« æ•°: {format_number(total_articles)}")
    print(f"âœ… å®é™…å®Œæˆ: {format_number(actual_completed)}")
    print()

    # å„é˜¶æ®µçŠ¶æ€
    print("ğŸ“‹ å„é˜¶æ®µçŠ¶æ€:")

    # 1. å¾…ä¸‹è½½
    pending = pipeline_stats['discovered_pending']
    if pending > 0:
        print(f"   ğŸ”µ å·²å‘ç°å¾…ä¸‹è½½: {format_number(pending)}")

    # 2. ä¸‹è½½ä¸­
    downloading = pipeline_stats['downloading']
    if downloading > 0:
        print(f"   ğŸŸ¡ ä¸‹è½½ä¸­: {format_number(downloading)}")

    # 3. å¾…æå–
    download_completed = pipeline_stats['download_completed']
    if download_completed > 0:
        print(f"   ğŸŸ  ä¸‹è½½å®Œæˆå¾…æå–: {format_number(download_completed)}")

    # 4. æå–ä¸­
    extracting = pipeline_stats['extracting']
    if extracting > 0:
        print(f"   ğŸŸ£ æå–ä¸­: {format_number(extracting)}")

    # 5. å…¨éƒ¨å®Œæˆ
    completed = pipeline_stats['completed']
    print(f"   ğŸŸ¢ å…¨éƒ¨å®Œæˆ: {format_number(completed)}")

    # 6. å¤±è´¥çŠ¶æ€
    failed_download = pipeline_stats['failed_download']
    failed_extraction = pipeline_stats['failed_extraction']
    if failed_download > 0:
        print(f"   ğŸ”´ ä¸‹è½½å¤±è´¥: {format_number(failed_download)}")
    if failed_extraction > 0:
        print(f"   ğŸ”´ æå–å¤±è´¥: {format_number(failed_extraction)}")

    # å®é™…æ–‡ä»¶çŠ¶æ€ï¼ˆæ–‡ä»¶ç³»ç»ŸçœŸå®æƒ…å†µï¼‰
    print()
    print("ğŸ“ å®é™…æ–‡ä»¶çŠ¶æ€:")
    html_count = pipeline_stats.get('html_count', 0)
    text_count = pipeline_stats.get('text_count', 0)

    print(f"   ğŸ“„ HTMLæ–‡ä»¶: {format_number(html_count)}")
    print(f"   ğŸ“ æ–‡æœ¬æ–‡ä»¶: {format_number(text_count)}")

    if html_count > 0 and text_count > 0:
        completion_rate = min(text_count / html_count * 100, 100)
        print(f"   ğŸ“ˆ æå–å®Œæˆç‡: {completion_rate:.1f}%")

def print_queue_details(pipeline_stats):
    """æ‰“å°é˜Ÿåˆ—è¯¦æƒ…"""
    print(f"\nğŸ”„ é˜Ÿåˆ—çŠ¶æ€è¯¦æƒ…")
    print("-" * 50)

    download_queue = pipeline_stats.get('queue_download_pending', 0)
    parse_queue = pipeline_stats.get('queue_parse_pending', 0)

    print(f"ğŸ“¥ ä¸‹è½½é˜Ÿåˆ—: {format_number(download_queue)} å¾…å¤„ç†")
    print(f"ğŸ“ è§£æé˜Ÿåˆ—: {format_number(parse_queue)} å¾…å¤„ç†")

    if download_queue == 0 and parse_queue == 0:
        print("   âœ¨ æ‰€æœ‰é˜Ÿåˆ—å·²æ¸…ç©º")
    elif download_queue > 0:
        print("   â„¹ï¸  ä¸‹è½½é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡å¯èƒ½æ˜¯:")
        print("      - æ–°å‘ç°çš„æ–‡ç« ")
        print("      - ä¸‹è½½å¤±è´¥éœ€é‡è¯•çš„æ–‡ç« ")
        print("      - çŠ¶æ€åŒæ­¥å»¶è¿Ÿçš„å·²å®Œæˆæ–‡ç« ")

def print_worker_status(services_info):
    """æ‰“å°å·¥ä½œè€…çŠ¶æ€"""
    print(f"\nğŸ‘· å·¥ä½œè€…çŠ¶æ€")
    print("-" * 50)

    # ä¸‹è½½æœåŠ¡å·¥ä½œè€…
    download_service = services_info.get('Download Service', {})
    if download_service.get('status') == 'online':
        data = download_service.get('data', {})
        worker_running = data.get('worker_running', False)
        stats = data.get('stats', {})

        status_icon = "ğŸŸ¢" if worker_running else "ğŸ”´"
        print(f"{status_icon} ä¸‹è½½å·¥ä½œè€…: {'è¿è¡Œä¸­' if worker_running else 'å·²åœæ­¢'}")

        last_run = stats.get('last_run')
        if last_run:
            processed = last_run.get('processed', 0)
            successful = last_run.get('successful', 0)
            failed = last_run.get('failed', 0)
            print(f"   æœ€è¿‘æ‰¹æ¬¡: å¤„ç†{processed}, æˆåŠŸ{successful}, å¤±è´¥{failed}")

    # æ–‡æœ¬æå–æœåŠ¡å·¥ä½œè€…
    extraction_service = services_info.get('Text Extraction Service', {})
    if extraction_service.get('status') == 'online':
        data = extraction_service.get('data', {})
        worker_running = data.get('worker_running', False)
        stats = data.get('stats', {})

        status_icon = "ğŸŸ¢" if worker_running else "ğŸ”´"
        print(f"{status_icon} æ–‡æœ¬æå–å·¥ä½œè€…: {'è¿è¡Œä¸­' if worker_running else 'å·²åœæ­¢'}")

        last_run = stats.get('last_run')
        if last_run:
            processed = last_run.get('processed', 0)
            successful = last_run.get('successful', 0)
            failed = last_run.get('failed', 0)
            print(f"   æœ€è¿‘æ‰¹æ¬¡: å¤„ç†{processed}, æˆåŠŸ{successful}, å¤±è´¥{failed}")

def print_summary(pipeline_stats, services_info):
    """æ‰“å°æ€»ç»“"""
    print(f"\nğŸ“‹ ç³»ç»Ÿæ€»ç»“")
    print("-" * 50)

    actual_completed = pipeline_stats['actual_completed']

    if actual_completed > 1000:
        print(f"ğŸ‰ å·²æˆåŠŸå¤„ç† {format_number(actual_completed)} ç¯‡æ–‡ç« ï¼")
    elif actual_completed > 0:
        print(f"âœ… å·²å¤„ç† {format_number(actual_completed)} ç¯‡æ–‡ç« ")
    else:
        print("â³ å¤„ç†è¿›ç¨‹åˆšå¼€å§‹")

    # æ£€æŸ¥è‡ªåŠ¨åŒ–çŠ¶æ€
    download_running = False
    extraction_running = False

    download_service = services_info.get('Download Service', {})
    if download_service.get('status') == 'online':
        download_running = download_service.get('data', {}).get('worker_running', False)

    extraction_service = services_info.get('Text Extraction Service', {})
    if extraction_service.get('status') == 'online':
        extraction_running = extraction_service.get('data', {}).get('worker_running', False)

    if download_running and extraction_running:
        print("ğŸ¤– è‡ªåŠ¨åŒ–æµç¨‹: å…¨éƒ¨æ¿€æ´»ï¼Œæ–°æ–‡ç« å°†è‡ªåŠ¨å¤„ç†")
    elif download_running or extraction_running:
        print("ğŸ¤– è‡ªåŠ¨åŒ–æµç¨‹: éƒ¨åˆ†æ¿€æ´»")
    else:
        print("ğŸ¤– è‡ªåŠ¨åŒ–æµç¨‹: æœªæ¿€æ´»")

def main():
    """ä¸»å‡½æ•°"""
    print_header()

    # å®šä¹‰è¦æ£€æŸ¥çš„æœåŠ¡
    services = {
        'Download Service': 'http://localhost:5003/status',
        'Text Extraction Service': 'http://localhost:5006/status'
    }

    # è·å–æœåŠ¡çŠ¶æ€
    services_info = {}
    for service_name, url in services.items():
        services_info[service_name] = get_service_status(url, service_name)

    # è·å–æ•°æ®åº“ç»Ÿè®¡
    db_stats = get_database_stats()

    # è·å–æ–‡ä»¶ç³»ç»Ÿç»Ÿè®¡
    file_stats = get_file_stats()

    # åˆ†æå¤„ç†æµæ°´çº¿
    pipeline_stats = analyze_processing_pipeline(services_info, db_stats, file_stats)
    pipeline_stats.update(file_stats)  # æ·»åŠ æ–‡ä»¶ç»Ÿè®¡

    # æ‰“å°å„éƒ¨åˆ†
    print_pipeline_status(pipeline_stats)
    print_queue_details(pipeline_stats)
    print_worker_status(services_info)
    print_summary(pipeline_stats, services_info)

    print("\n" + "=" * 80)
    print("ğŸ’¡ æç¤º:")
    print("  - é‡æ–°æ£€æŸ¥: python check_detailed_status.py")
    print("  - ç®€å•çŠ¶æ€: ./status")
    print("  - æ–‡ä»¶ä½ç½®: /tmp/genesis-content/text/")
    print("  - ä¸‹è½½çŠ¶æ€: curl -s http://localhost:5003/status")
    print("  - æå–çŠ¶æ€: curl -s http://localhost:5006/status")

if __name__ == "__main__":
    main()